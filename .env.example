# Required: LLM Model Name (e.g., openai/gpt-4o, anthropic/claude-3-5-sonnet-20240620)
STRIX_LLM=openai/gpt-4o

# Optional: LLM API Key (Required for cloud providers like OpenAI, Anthropic, etc.)
# Not needed for local models or if using other authentication methods (e.g., Vertex AI, AWS)
LLM_API_KEY=your_api_key_here

# Optional: Custom API Base URL (Useful for local models via Ollama, LMStudio, etc.)
# Equivalents: OPENAI_API_BASE, LITELLM_BASE_URL, OLLAMA_API_BASE
# LLM_API_BASE=http://localhost:11434

# Optional: Perplexity API Key (Enables real-time web search/research capabilities)
PERPLEXITY_API_KEY=your_perplexity_key_here

# Optional: LLM Timeout in seconds (Default: 600)
# LLM_TIMEOUT=600

# Optional: Docker Configuration
# DOCKER_HOST=unix:///var/run/docker.sock
# STRIX_IMAGE=strix/sandbox:latest

# Optional: Proxy Configuration (if using Caido)
# CAIDO_PORT=8080
# CAIDO_API_TOKEN=your_caido_token
